{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Loading audio...\n",
      "Total duration: 243.22 seconds\n",
      "Normalizing audio...\n",
      "Loading pre-trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchaudio/pipelines/_source_separation_pipeline.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n",
      "Separating sources in batches...\n",
      "Preparing segment from 0.00s to 30.00s\n",
      "Preparing segment from 25.00s to 55.00s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Preparing segment from 50.00s to 80.00s\n",
      "Preparing segment from 75.00s to 105.00s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Preparing segment from 100.00s to 130.00s\n",
      "Preparing segment from 125.00s to 155.00s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Preparing segment from 150.00s to 180.00s\n",
      "Preparing segment from 175.00s to 205.00s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Preparing segment from 200.00s to 230.00s\n",
      "Preparing segment from 225.00s to 243.22s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Separated sources shape: torch.Size([4, 2, 11674624])\n",
      "Storing separated sources into a dictionary...\n",
      "Sources extracted by the model: ['drums', 'bass', 'other', 'vocals']\n",
      "Separated sources keys: ['drums', 'bass', 'other', 'vocals']\n",
      "Analyzing and outputting results...\n",
      "\n",
      "Processing source: drums\n",
      "Shape of predicted_source for drums: torch.Size([2, 11674624])\n",
      "Saved drums to ./assets/drums_full_song.wav\n",
      "\n",
      "Processing source: bass\n",
      "Shape of predicted_source for bass: torch.Size([2, 11674624])\n",
      "Saved bass to ./assets/bass_full_song.wav\n",
      "\n",
      "Processing source: other\n",
      "Shape of predicted_source for other: torch.Size([2, 11674624])\n",
      "Saved other to ./assets/other_full_song.wav\n",
      "\n",
      "Processing source: vocals\n",
      "Shape of predicted_source for vocals: torch.Size([2, 11674624])\n",
      "Saved vocals to ./assets/vocals_full_song.wav\n",
      "\n",
      "Source separation completed successfully!\n",
      "\n",
      "Total time taken: 10.35 seconds\n"
     ]
    }
   ],
   "source": [
    "from source_separation import *\n",
    "\n",
    "run_source_separation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Loading audio...\n",
      "Total duration: 243.22 seconds\n",
      "Normalizing audio...\n",
      "Loading pre-trained model...\n",
      "Using 2 GPUs\n",
      "Separating sources in batches...\n",
      "Preparing segment from 0.00s to 30.00s\n",
      "Preparing segment from 25.00s to 55.00s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Preparing segment from 50.00s to 80.00s\n",
      "Preparing segment from 75.00s to 105.00s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Preparing segment from 100.00s to 130.00s\n",
      "Preparing segment from 125.00s to 155.00s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Preparing segment from 150.00s to 180.00s\n",
      "Preparing segment from 175.00s to 205.00s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Preparing segment from 200.00s to 230.00s\n",
      "Preparing segment from 225.00s to 243.22s\n",
      "Processing a batch of 2 segments on device: cuda:0\n",
      "Added separated source from segment 1 in batch\n",
      "Added separated source from segment 2 in batch\n",
      "Separated sources shape: torch.Size([4, 2, 11674624])\n",
      "Storing separated sources into a dictionary...\n",
      "Sources extracted by the model: ['drums', 'bass', 'other', 'vocals']\n",
      "Separated sources keys: ['drums', 'bass', 'other', 'vocals']\n",
      "Analyzing and outputting results...\n",
      "\n",
      "Processing source: drums\n",
      "Shape of predicted_source for drums: torch.Size([2, 11674624])\n",
      "Saved drums to ./assets/drums_full_song.wav\n",
      "\n",
      "Processing source: bass\n",
      "Shape of predicted_source for bass: torch.Size([2, 11674624])\n",
      "Saved bass to ./assets/bass_full_song.wav\n",
      "\n",
      "Processing source: other\n",
      "Shape of predicted_source for other: torch.Size([2, 11674624])\n",
      "Saved other to ./assets/other_full_song.wav\n",
      "\n",
      "Processing source: vocals\n",
      "Shape of predicted_source for vocals: torch.Size([2, 11674624])\n",
      "Saved vocals to ./assets/vocals_full_song.wav\n",
      "\n",
      "Source separation completed successfully!\n",
      "\n",
      "Total time taken: 7.49 seconds\n",
      "\n",
      "Playing drums_full_song.wav:\n"
     ]
    }
   ],
   "source": [
    "# Import the Audio and display functions\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Access the sources list from your model\n",
    "# Ensure that this matches how you've defined or imported your model\n",
    "bundle = HDEMUCS_HIGH_MUSDB_PLUS\n",
    "model = bundle.get_model()\n",
    "sources_list = model.sources\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = './assets'\n",
    "\n",
    "# Iterate over each source and display the audio player\n",
    "for source_name in sources_list:\n",
    "    file_name = f\"{source_name}_full_song.wav\"\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "    print(f\"\\nPlaying {file_name}:\")\n",
    "    display(Audio(file_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
